{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 你的深度学习之旅\n",
    "您好，感谢您让我们加入您的深度学习之旅，无论您走得多远！\n",
    "在本章中，我们将告诉您更多关于本书的期望，介绍深度学习背后的关键概念，并针对不同的任务训练我们的第一个模型。\n",
    "如果你没有技术或者数学背景，没有关系，我们写这本书是为了让尽可能多的人能够进行深度学习。\n",
    "# 深度学习适合每个人\n",
    "很多人认为你需要各种难以找到的东西才能在深度学习中取得好成绩，但正如你在这本书中看到的那样，那些人错了。\n",
    "下面列出了一些你绝对不需要做的世界级深度学习的事情。\n",
    "| 虚假情况 (不需要)      | 真实情况 |\n",
    "| ----------- | ----------- |\n",
    "| 大量数学知识 | 高中数学知识足够了\n",
    "| 大量的数据 | 我们已经看到了破纪录的结果，数据少于50项\n",
    "| 大量昂贵的计算机 | 你可以免费获得你需要的最先进的作品\n",
    "\n",
    "深度学习是一种通过使用多层神经网络来提取和转换数据的计算机技术，其用例从人类语音识别到动物图像分类。神经网络的每一层都从前一层中获取输入，并逐步细化它们。这些层是通过算法进行训练的，这些算法可以最大限度地减少它们的误差并提高它们的准确性。通过这种方式，网络学习执行指定的任务。我们将在下一节中详细讨论训练算法。\n",
    "\n",
    "深度学习具有强大、灵活和简单的特点。这就是为什么我们认为它应该被应用于许多学科。这些学科包括社会和物理科学、艺术、医学、金融、科学研究等等。举个例子，尽管没有医学背景，Jeremy还是创办了Enlitic，一家使用深度学习算法来诊断疾病的公司。该公司在创办的几个月内，就宣布其算法可以比放射科医生更准确地识别恶性肿瘤。\n",
    "\n",
    "这里列出了不同领域的数千项任务，在这些任务中，深度学习或大量使用深度学习的方法，现在是世界上最好的：\n",
    "- 自然语言处理（NLP）：回答问题；语音识别；总结文件；对文件进行分类；查找文件中的名称、日期等；搜索提到某一概念的文章\n",
    "- 计算机视觉：卫星和无人机图像解读（例如，用于抗灾）；人脸识别；图像字幕；阅读交通标志；在自动驾驶车辆中定位行人和车辆\n",
    "- 医学：在放射学图像中发现异常，包括CT、MRI和X射线图像；计算病理切片中的特征；测量超声波中的特征；诊断糖尿病性视网膜病变\n",
    "- 生物学：折叠蛋白质；对蛋白质进行分类；许多基因组学任务，如肿瘤正常测序和对临床上可操作的基因突变进行分类；细胞分类；分析蛋白质/蛋白质的相互作用\n",
    "- 图像生成：对图像进行着色；提高图像分辨率；去除图像中的噪音；将图像转换为著名艺术家风格的艺术。\n",
    "- 推荐系统：网络搜索；产品推荐；主页布局\n",
    "- 玩游戏：国际象棋、围棋、大多数雅达利视频游戏，以及许多实时战略游戏\n",
    "- 机器人：处理具有挑战性的物体（例如，透明的、有光泽的、缺乏质地的）或难以拿起的物体\n",
    "- 其他应用：金融和物流预测，文本到语音，以及更多......\n",
    "难能可贵的是，深度学习有如此多样的应用，但几乎所有的深度学习都是基于单一类型的模型，即神经网络。\n",
    "但神经网络事实上并不是什么全新的事物。为了对该领域有一个更广泛的视角，值得从一点历史开始。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: A Brief History\n",
    "\n",
    "1943年，神经生理学家沃伦-麦库洛赫和逻辑学家沃尔特-皮茨合作开发了一个人工神经元的数学模型。在他们的论文 \"A Logical Calculus of the Ideas Immanent in Nervous Activity \"中，他们宣称：\n",
    "```                 \n",
    "由于神经活动的\"全或无\"特性，神经事件和它们之间的关系可以用命题逻辑来处理。人们发现，每个网的行为都可以用这些术语来描述。\n",
    "```\n",
    "\n",
    "麦库洛赫和皮茨意识到，一个真实神经元的简化模型可以用简单的加法和阈值表示，如下图所示。皮茨是自学成才的，在12岁时，他收到了去剑桥大学跟随伟大的伯特兰-罗素学习的邀请。他没有接受这个邀请，实际上在他的一生中也没有接受任何高级学位或权威职位的邀请。他的大部分著名作品都是在无家可归时完成的。尽管他没有得到官方认可的职位，而且越来越被社会孤立，但他与麦库洛赫的工作很有影响，并被一位名叫弗兰克-罗森布拉特的心理学家所采纳。\n",
    "\n",
    "![自然和人工神经元](../images/01.intro/neuron.png \"自然和人工神经元\")\n",
    "\n",
    "罗森布拉特进一步发展了人工神经元，使其具有学习能力。更重要的是，他致力于建造第一个真正使用这些原理的设备，即马克一号感知机。在《The Design of an Intelligent Automaton》中，罗森布拉特写到了这项工作：“我们现在即将见证这样一种机器的诞生————一种能够感知、认识和识别周围环境，而不需要任何人类训练或控制的机器”。感知机建成后，能够成功识别简单的形状。\n",
    "\n",
    "麻省理工学院一位名叫马文-明斯基的教授（他在同一所高中比罗森布拉特低一个年级！），与西摩-帕珀特一起写了一本名为《Perceptrons》（麻省理工学院出版社）的书，讲述了罗森布拉特的发明。他们表明，这些单层感知机无法学习一些简单但关键的数学功能（如异或）。在同一本书中，他们还表明，使用多层感知机将使这些限制得到解决。不幸的是，只有这些见解中的第一个被广泛认可。因此，在接下来的二十年里，全球学术界几乎完全放弃了对神经网络的研究。\n",
    "\n",
    "在过去的50年里，神经网络方面最关键的工作也许是David Rumelhart、James McClellan和PDP研究小组的多卷本《Parallel Distributed Processing》（PDP），由麻省理工学院出版社于1986年发行。第一章阐述了与罗森布拉特所展示的类似的希望：\n",
    "```\n",
    "人们比今天的计算机更聪明，因为大脑采用了一种基本的计算架构，它更适合处理人们所擅长的自然信息处理任务的一个核心方面......我们将介绍一个用于认知过程建模的计算框架，该框架似乎......比其他框架更接近于大脑可能完成的计算风格。\n",
    "```\n",
    "PDP在这里使用的前提是，传统的计算机程序与大脑的工作方式非常不同，这可能就是为什么计算机程序（在当时）在做大脑认为很容易的事情（如识别图片中的物体）方面如此糟糕。作者声称，PDP方法“比其他框架更接近”大脑的工作方式，因此它可能更好地处理这些类型的任务。\n",
    "\n",
    "事实上，PDP中规定的方法与今天的神经网络中使用的方法非常相似。该书将并行分布式处理定义为要求:\n",
    "\n",
    "In fact, the approach laid out in PDP is very similar to the approach used in today's neural networks. The book defined parallel distributed processing as requiring:\n",
    "1. 一组处理单元\n",
    "2. 一个激活的状态\n",
    "3. 每个单元的输出函数\n",
    "4. 单元之间的连接模式\n",
    "5. 一个通过连接网络传播活动模式的传播规则\n",
    "6. 一个激活规则，用于将影响一个单元的输入与该单元的当前状态相结合，为该单元产生一个输出\n",
    "7. 一个学习规则，通过经验改变连接模式。\n",
    "8. 一个系统必须在其中运行的环境\n",
    "\n",
    "我们将在本书中看到，现代神经网络可以满足这些要求中的每一项。\n",
    "\n",
    "在20世纪80年代，大多数模型都是用两层神经网络建立的，从而避免了明斯基和帕珀特发现的问题（这是他们的“单元之间的连接模式”，使用上面的框架）。而事实上，在80年代和90年代，神经网络被广泛用于真正的、实用的项目。然而，对理论问题的误解再次阻碍了该领域的发展。在理论上，只需增加一层额外的神经元，就足以让这些神经网络近似任何数学函数，但在实践中，这样的网络往往太大、太慢而无法发挥作用。\n",
    "\n",
    "尽管研究人员在30年前就表明，要想获得实用的良好性能，就需要使用更多的神经元层，但直到最近十年，这一原则才得到了更广泛的重视和应用。由于使用了更多的层，再加上计算机硬件的改进、数据可用性的增加以及允许神经网络更快、更容易地被训练的算法调整，神经网络现在终于发挥了其潜力。我们现在有了罗森布拉特承诺的东西： \"一台能够感知、识别和确认其周围环境的机器，不需要任何人类训练或控制\"。\n",
    "\n",
    "这就是你将在本书中学习如何建造的东西。但首先，由于我们将花很多时间在一起，让我们互相了解一下......\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我们是谁\n",
    "\n",
    "我们是西尔万和杰里米，你在这一旅程中的向导。我们希望你会发现我们很适合这个职位。\n",
    "\n",
    "杰里米使用并教授机器学习大约有30年了。他在25年前开始使用神经网络。在此期间，他领导了许多以机器学习为核心的公司和项目，包括创立了第一家专注于深度学习和医学的公司Enlitic，并担任了世界上最大的机器学习社区Kaggle的总裁和首席科学家。他与瑞秋-托马斯博士是fast.ai的共同创始人，该组织建立了本书所基于的课程。\n",
    "\n",
    "你会不时地听到我们的声音，比如杰里米的这篇侧记：\n",
    "```\n",
    "J：大家好，我是杰里米！你们可能有兴趣知道，我没有受过任何正式的技术教育。我完成了学士学位，主修哲学，但成绩并不出色。我对做实际项目更感兴趣，而不是理论研究，所以我在大学期间一直在一家叫麦肯锡的管理咨询公司全职工作。如果你是一个宁愿弄脏自己的手来建造东西也不愿花几年时间学习抽象概念的人，那么你会理解我的想法 请注意我的侧记，以找到最适合具有较少数学或正式技术背景的人的信息--也就是说，像我这样的人......\n",
    "```\n",
    "\n",
    "另一方面，西尔万对正规的技术教育非常了解。事实上，他已经写了10本数学教科书，涵盖了整个法国的高级数学课程！\n",
    "```\n",
    "S: 与杰里米不同的是，我没有花很多年时间编码和应用机器学习算法。相反，我是最近通过观看杰里米的fast.ai课程视频进入机器学习领域的。所以，如果你是一个没有打开过终端，没有在命令行上写过命令的人，那么你会明白我的来历。请注意我的侧边栏，以找到最适合具有更多数学或正式技术背景，但实际编码经验较少的人的信息，也就是像我这样的人......\n",
    "```\n",
    "\n",
    "fast.ai课程已经有数十万学生学习过，他们来自各行各业，来自世界各地。西尔万脱颖而出，成为杰里米所见过的课程中最令人印象深刻的学生，这导致他加入fast.ai，然后与杰里米一起成为fastai软件库的共同作者。\n",
    "\n",
    "所有这一切意味着，在我们之间，你拥有两个世界中最好的东西：比其他人更了解软件的人，因为是他们写的；一个数学专家，一个编码和机器学习的专家；还有一个人，他们既了解在数学方面成为相对局外人的感觉，也了解在编码和机器学习方面成为相对局外人的感觉。\n",
    "\n",
    "看过体育比赛的人都知道，如果你有一个两人的解说团队，那么你还需要一个第三人做 \"特别评论\"。我们的特别评论员是亚历克西斯·加拉赫。亚历克西斯的背景非常多样化：他曾是数学生物学研究员、剧本作家、即兴表演者、麦肯锡顾问（像杰里米！）、Swift编码员和CTO。\n",
    "\n",
    "```\n",
    "A：我已经决定是时候学习人工智能这东西了！毕竟，我已经尝试了几乎所有其他的东西！毕竟，我已经尝试了其他所有的东西......但我并没有建立机器学习模型的背景。不过......这能有多难？我将在本书中不断学习，就像你一样。请留意我的侧边栏，了解我在学习过程中发现的有用的学习技巧，希望你也会发现有帮助。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何学习深度学习\n",
    "\n",
    "哈佛大学教授大卫-帕金斯（David Perkins）写了《Making Learning Whole》（Jossey-Bass）一书，他对教学有很多话要说。其基本思想是教授整个游戏。这意味着，如果你要教棒球，你首先要带人们去看棒球比赛或让他们玩棒球。你不会教他们如何用麻绳从头开始做一个棒球，也不会教他们抛物线的物理学原理，或者球在球棒上的摩擦系数。\n",
    "\n",
    "哥伦比亚大学数学博士、前布朗大学教授、K-12数学教师保罗-洛克哈特（Paul Lockhart）在一篇颇具影响力的文章《A Mathematician's Lament》中想象了一个噩梦般的世界，在那里，音乐和艺术的教学方式与数学的教学方式相同。孩子们在花了十几年的时间掌握音乐符号和理论之前，不允许听或玩音乐，要花时间把乐谱换成不同的调。在艺术课上，学生们学习颜色和涂抹器，但直到大学才被允许真正作画。听起来很荒唐？这就是数学的教学方式————我们要求学生花数年时间死记硬背，学习枯燥无味、互不相干的基础知识，我们声称这些知识以后会有回报，而且是在他们中的大多数人退出这个学科之后很久。\n",
    "\n",
    "不幸的是，这就是许多关于深度学习的教学资源开始的地方————要求学习者跟随Hessian的定义和损失函数的泰勒近似定理，而没有给出实际工作代码的例子。我们不是在嘲笑微积分。我们喜欢微积分，Sylvain甚至在大学里也教过它，但我们认为在学习深度学习时，它并不是最好的开始！\n",
    "\n",
    "在深度学习中，如果你有动力去修复你的模型，让它做得更好，这真的很有帮助。这就是你开始学习相关理论的时候。但你首先需要有模型。我们几乎所有的东西都是通过真实的例子来教的。随着我们建立起这些例子，我们会越来越深入，我们会告诉你如何使你的项目越来越好。这意味着你将逐步学习你所需要的所有理论基础，在这个过程中，你会看到为什么它很重要，它是如何工作的。\n",
    "\n",
    "因此，这里是我们对你的承诺。在本书中，我们将遵循这些原则：\n",
    "\n",
    "- 教授整个游戏。我们将从展示如何使用一个完整的、可操作的、非常可用的、最先进的深度学习网络开始，使用简单的、可表达的工具来解决现实世界的问题。然后我们会逐渐深入了解这些工具是如何制作的，以及制作这些工具的工具是如何制作的，等等......\n",
    "\n",
    "- 始终通过实例进行教学。我们会确保有一个你能直观理解的背景和目的，而不是从代数符号的操作开始。\n",
    "\n",
    "- 尽可能地简化。我们已经花了多年时间建立工具和教学方法，使以前复杂的主题变得非常简单。\n",
    "\n",
    "- 消除障碍。到目前为止，深度学习一直是一个非常独特的游戏。我们正在打破它，并确保每个人都能玩。\n",
    "\n",
    "深度学习最难的部分是工匠精神：你怎么知道你是否有足够的数据，数据的格式是否正确，你的模型是否在正常训练，如果不正确，你应该怎么做？这就是为什么我们相信在实践中学习。就像基本的数据科学技能一样，对于深度学习，你只有通过实践经验才能变得更好。试图在理论上花费太多时间可能会适得其反。关键是编写代码并尝试解决问题：理论可以当你有背景和动机的时候再来研究。\n",
    "\n",
    "这段旅程有些时候会很艰难。有的时候，你会觉得被卡住了。不要放弃! 倒回去看书，找到最后一点你肯定没有卡住的地方，然后从那里慢慢读下去，找到第一件不清楚的事情。然后自己尝试一些代码实验，并在谷歌上搜索更多的教程，不管你遇到的问题是什么————通常你会发现一些不同角度的材料可能会有助于你。另外，在第一次阅读时不能理解所有的东西（尤其是代码）是正常的。试图在继续学习之前连续地理解材料有时是很难的。有时，当你从下一阶段的部分内容中获得更多的信息，从更大的画面中获得更多的东西后，事情就会被点击到位。因此，如果你确实在某一节上卡住了，无论如何都要试着继续前进，并记下以后再来找它。\n",
    "\n",
    "记住，你不需要任何特定的学术背景就能在深度学习方面取得成功。许多重要的突破是由没有博士学位的人在研究和工业中取得的，例如《Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks》————过去十年中最有影响力的论文之一，有超过5000次的引用，这是由Alec Radford在他还是本科生时写的。即使是在特斯拉，他们也在努力解决制造自动驾驶汽车这一极其艰难的挑战，首席执行官埃隆-马斯克说：\n",
    "\n",
    "```\n",
    "博士学位绝对不是必需的。重要的是对人工智能的深刻理解和以实际有用的方式落实神经网络的能力（后一点才是真正的困难）。甚至不在乎你是否高中毕业。\n",
    "```\n",
    "\n",
    "然而，你需要做的是将你在本书中学到的东西应用到个人项目中，并始终坚持下去，才能取得成功。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 你的项目和你的心态\n",
    "\n",
    "无论你是想通过植物的叶子来识别植物是否有病，自动生成针织图案，通过X射线诊断肺结核，还是确定浣熊何时使用你的猫门，我们都会让你尽快在自己的问题上使用深度学习（通过别人的预训练模型），然后会逐步钻研更多的细节。在下一章的前30分钟内，你将学会如何使用深度学习来解决你自己的问题，并达到最先进的精度 (如果你很想马上开始编程的话，可以直接跳过这里）。外面有一个恶毒的神话，说你需要拥有像谷歌那样的计算资源和数据集才能进行深度学习，但这不是真的。\n",
    "\n",
    "那么，什么样的任务才是好的测试案例？你可以训练你的模型来区分毕加索和莫奈的画，或者挑选出你女儿的照片而不是你儿子的照片。专注于你的爱好和激情是有帮助的————为自己设定四五个小项目，而不是努力解决一个大的、宏大的问题，这在你开始的时候往往效果更好。因为很容易被卡住，所以过早地尝试雄心勃勃的任务往往会适得其反。然后，一旦你掌握了基础知识，就以完成你真正引以为豪的东西为目标!\n",
    "\n",
    "```\n",
    "J: 深度学习几乎可以被设置为处理任何问题。例如，我的第一家创业公司是一家名为FastMail的公司，它在1999年推出时提供了强化的电子邮件服务（直到今天仍然如此）。2002年，我把它设定为使用深度学习的原始形式，即单层神经网络，以帮助对电子邮件进行分类并阻止客户收到垃圾邮件。\n",
    "```\n",
    "\n",
    "在深度学习方面表现出色的人的共同性格特征包括玩心和好奇心。已故物理学家理查德-费曼（Richard Feynman）是我们期望在深度学习方面表现出色的人的一个例子：他对亚原子粒子运动的理解的发展来自于他对盘子在空中旋转时如何摇晃的乐趣。\n",
    "\n",
    "现在让我们把重点放在你将学到的东西上，首先是软件。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 软件：pytorch，fastai和Jupyter\n",
    "(以及为什么它不重要)\n",
    "\n",
    "我们已经完成了数百个机器学习项目，使用了几十个不同的软件包，以及许多不同的编程语言。在fast.ai，我们使用目前使用的大多数主要深度学习和机器学习软件包编写了课程。2017年PyTorch问世后，我们花了一千多个小时测试它，然后决定将其用于未来的课程、软件开发和研究。从那时起，PyTorch已经成为世界上增长最快的深度学习库，并且已经被用于顶级会议的大多数研究论文。这通常是行业使用情况的领先指标，因为这些论文最终会被用于产品和服务的商业化。我们发现，PyTorch是最灵活、最具表现力的深度学习库。它不会以速度为代价来换取简单性，而是两者都提供。\n",
    "\n",
    "PyTorch作为一个效果最好的低层次的基础库，为更高层次的功能提供基础操作。fastai库是在PyTorch基础上添加这种高层次功能的最流行的库。它也特别适合本书的目的，因为它在提供深度分层的软件架构方面是独一无二的（甚至有一篇关于这种分层API的同行评审的学术论文）。在本书中，随着我们对深度学习的基础越来越深入，我们也将越来越深入地了解fastai的层级。本书涵盖了fastai库的第二版，它是一次从头开始的重写，提供了许多独特的功能。\n",
    "\n",
    "然而，学习什么软件其实并不重要，因为从一个库切换到另一个库，只需要几天时间就能学会。真正重要的是正确学习深度学习的基础和技术。我们的重点将是使用代码明确表达你需要学习的概念。在我们教授高级概念的地方，我们将使用高级的fastai代码。在教授低层次概念的地方，我们将使用低层次的PyTorch，甚至是纯Python代码。\n",
    "\n",
    "如果现在感觉新的深度学习库正在快速出现，那么你需要做好准备，在未来几个月和几年里，变化的速度会更快。随着越来越多的人进入这个领域，他们会带来更多的技能和想法，并尝试更多的东西。你应该假定，无论你今天学习什么具体的库和软件，在一两年内就会被淘汰。试想一下，在网络编程的世界里，库和技术栈的数量一直在发生变化————这是一个比深度学习更成熟、发展更缓慢的领域。我们坚信，学习的重点需要放在理解基础技术和如何在实践中应用它们上，以及如何在新工具和新技术发布时快速建立专业知识。\n",
    "\n",
    "在本书结束时，你将了解fastai（以及PyTorch的大部分）内的几乎所有代码，因为在每一章中，我们将深入挖掘，向你展示我们在构建和训练模型时的确切情况。这意味着你将学到现代深度学习中使用的最重要的最佳实践————不仅仅是如何使用它们，而是它们真正的工作和实现方式。如果你想在另一个框架中使用这些方法，你将拥有必要的知识来做到这一点。\n",
    "\n",
    "由于学习深度学习最重要的是写代码和做实验，所以有一个很好的代码实验平台是很重要的。最流行的编程实验平台被称为Jupyter。这就是我们将在本书中使用的东西。我们将向你展示如何使用Jupyter来训练和实验模型，并对数据预处理和模型开发流程的每个阶段进行反省。Jupyter Notebook是在Python中进行数据科学的最流行的工具，这是有原因的。它强大、灵活，而且易于使用。我们认为你会喜欢它！\n",
    "\n",
    "让我们在实践中看看，训练我们的第一个模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 你的第一个模型\n",
    "\n",
    "正如我们之前所说的，我们将在解释它们为什么有效之前教你如何做事情。按照这种自上而下的方法，我们将首先实际训练一个图像分类器，以几乎100%的准确率识别狗和猫。为了训练这个模型并运行我们的实验，你将需要做一些初始设置。别担心，这并不像看起来那么难。\n",
    "\n",
    "```\n",
    "s: 不要跳过设置部分，即使它一开始看起来很吓人，特别是如果你很少或没有使用终端或命令行等东西的经验。实际上大部分都是没有必要的，你会发现最简单的服务器可以只用你常用的网络浏览器就能设置好。为了学习，你在阅读本书的同时进行自己的实验，这一点至关重要。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取一台GPU深度学习服务器\n",
    "\n",
    "要完成本书中的几乎所有内容，你需要使用一台带有NVIDIA GPU的计算机（不幸的是，其他品牌的GPU并不完全被主要的深度学习库所支持）。然而，我们并不建议你买一个；事实上，即使你已经有一个，我们也不建议你现在就使用它。设置一台电脑需要时间和精力，而你现在想把所有的精力都放在深度学习上。因此，我们建议你租用一台已经预装了所有你需要的东西并准备就绪的电脑。在你使用时，费用可以低至每小时0.25美元，有些选项甚至是免费的。\n",
    "\n",
    "```\n",
    "术语：图形处理单元（GPU）：也被称为显卡。计算机中一种特殊的处理器，可以同时处理成千上万的单一任务，特别是为在计算机上显示3D环境玩游戏而设计。这些相同的基本任务与神经网络的工作非常相似，这样，GPU运行神经网络的速度比普通CPU快数百倍。所有现代计算机都包含一个GPU，但很少有包含深度学习所需的正确类型的GPU。\n",
    "```\n",
    "随着公司的出现和价格的变化，与本书一起使用的GPU服务器的最佳选择将随着时间的推移而改变。我们在本书的网站上维护了一个我们推荐的选项列表，所以现在就去那里，按照说明连接到GPU深度学习服务器。别担心，在大多数平台上只需要两分钟就能设置好，而且许多平台甚至不需要任何付款，甚至不需要信用卡就能开始。\n",
    "```\n",
    "A：我的两分钱：听从这个建议! 如果你喜欢计算机，你会被诱惑去设置你自己的盒子。请注意！这是可行的！它是可行的，但令人惊讶的是，它涉及到了很多问题，而且让人分心。这本书不叫《你想知道的关于Ubuntu系统管理、NVIDIA驱动程序安装、apt-get、conda、pip和Jupyter笔记本配置的一切》是有原因的。那将是一本属于自己的书。我在工作中设计并部署了我们的生产型机器学习基础设施，我可以证明它有其令人满意的地方，但它与建模的关系就像维护飞机与驾驶飞机一样不相关。\n",
    "```\n",
    "\n",
    "网站上显示的每个选项都包括一个教程；完成教程后，你最终会看到一个看起来像下图的网页。\n",
    "![](../images/01.intro/notebook_init.png \"Initial view of Jupyter Notebook\")\n",
    "\n",
    "现在你已经准备好运行你的第一个Jupyter笔记了！\n",
    "```\n",
    "术语：Jupyter笔记本：一款允许你在一个单一的交互式文档中包含格式化文本、代码、图像、视频等等的软件。Jupyter获得了软件的最高荣誉————ACM软件系统奖，这得益于它在许多学术领域和工业界的广泛使用和巨大影响。Jupyter笔记本是数据科学家最广泛使用的软件，用于开发深度学习模型并与之互动。\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行你的第一个笔记\n",
    "\n",
    "笔记按章节标示，然后按笔记编号标示，所以它们的顺序与本书中呈现的顺序相同。因此，你将看到列出的第一个笔记是你现在需要使用的笔记。你将使用这个笔记来训练一个能够识别狗和猫照片的模型。要做到这一点，你将下载一个狗和猫照片的数据集，并使用它来训练一个模型。数据集只是一堆数据————它可以是图像、电子邮件、金融指标、声音或其他任何东西。有许多数据集是免费提供的，适用于训练模型。其中许多数据集是由学术界创建的，以帮助推进研究，许多是为比赛提供的（有一些比赛，数据科学家可以竞争，看谁的模型最准确！），还有一些是其他过程的副产品（如财务申报）。\n",
    "\n",
    "```\n",
    "注：完整的和清零的笔记本：有两个文件夹包含不同版本的笔记本。完整的文件夹包含用于创建你现在正在阅读的这本书的确切笔记本，包括所有的内容和输出。清零的版本有相同的标题和代码单元，但所有输出和内容都已被删除。在阅读完本书的某一章节后，我们建议在关闭书本的情况下，通过清零后的笔记本，看看你是否能在执行前弄清楚每个单元格会显示什么。还可以试着回忆一下代码所演示的内容。\n",
    "```\n",
    "\n",
    "要打开一个笔记本，只需点击它。笔记本将被打开，它看起来就像下图（注意，不同的平台在细节上可能有轻微的差异，你可以忽略这些差异）。\n",
    "\n",
    "![](../images/01.intro/jupyter_open.png \"An example of notebook\")\n",
    "\n",
    "A notebook consists of cells. There are two main types of cell:\n",
    "一本笔记本包含多个单元格。有两种主要类型的单元格：\n",
    "- 包含格式化文本、图像等的单元格。这些单元格使用一种叫做markdown的格式，你很快就会了解到。\n",
    "- 包含可以执行的代码的单元格，输出会紧接着出现在下面（可以是纯文本、表格、图像、动画、声音，甚至是交互式应用程序）。\n",
    "\n",
    "Jupyter笔记本可以处于两种模式中的一种：编辑模式或命令模式。在编辑模式下，用键盘打字，以常规方式将字母输入单元格。然而，在命令模式下，你不会看到任何闪动的光标，键盘上的每个键都会有特殊的功能。\n",
    "\n",
    "在继续之前，请按键盘上的Escape键切换到命令模式（如果你已经在命令模式下，这没有任何作用，所以现在按它只是以防万一）。要查看所有可用功能的完整列表，请按H键；按Escape键可以删除这个帮助屏幕。注意，在命令模式下，与大多数程序不同，命令不需要你按住Control、Alt或类似的键，你只需按下所需的字母键。\n",
    "\n",
    "你可以按C键复制一个单元格（首先需要选择该单元格，用周围的轮廓表示；如果还没有选择，点击一次）。然后按V键来粘贴它的副本。\n",
    "\n",
    "点击以“# CLICK ME”一行开头的单元格来选择它。该行的第一个字符表示后面的内容是Python中的注释，所以在执行单元格时它被忽略了。不管你信不信，该单元格的其余部分是一个完整的系统，用于创建和训练一个最先进的识别猫和狗的模型。那么，我们现在就来训练它吧! 要做到这一点，只需按键盘上的Shift-Enter键，或按工具栏上的运行按钮。然后等待几分钟，以下事情就会发生：\n",
    "\n",
    "1. 一个名为“Oxford-IIIT”的宠物数据集，包含37个不同品种的猫和狗的7,349张图像，将从fast.ai数据集集合中下载到你正在使用的GPU服务器上，然后将被提取出来。\n",
    "2. 一个已经在130万张图片上训练过的预训练模型将从互联网上下载，该模型使用一个竞赛获奖的模型。\n",
    "3. 预训练的模型将利用迁移学习的最新进展进行微调，以创建一个为识别猫狗而特别定制的模型。\n",
    "\n",
    "前两个步骤只需要在你的GPU服务器上运行一次。如果你再次运行该单元，它将使用已经下载的数据集和模型，而不是再次下载它们。让我们看看单元格的内容，以及结果：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhulin/anaconda3/envs/fastai/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/zhulin/anaconda3/envs/fastai/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#id first_training\n",
    "#caption Results from the first training\n",
    "# CLICK ME\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch     train_loss  valid_loss  error_rate  time    \n",
    "0         0.173193    0.011481    0.003383    00:11                                        \n",
    "epoch     train_loss  valid_loss  error_rate  time    \n",
    "0         0.057712    0.014689    0.004736    00:12  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可能不会看到与书中完全相同的结果。在训练模型中，有很多小的随机变化的来源。然而，在这个例子中，我们一般看到的错误率远低于0.02。\n",
    "\n",
    "```\n",
    "重点：训练时间： 根据你的网络速度，下载预训练的模型和数据集可能需要几分钟的时间。运行fine_tune可能需要1分钟左右。本书中的模型通常需要几分钟的时间来训练，你自己的模型也是如此，所以想出好办法来充分利用这段时间是个不错的主意。例如，在你的模型训练时继续阅读下一节，或者打开另一个笔记，用它做一些编码实验。\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 题外话：这本书是用Jupyter笔记本写的\n",
    "\n",
    "我们使用Jupyter笔记本来写这本书，所以对于本书中几乎每一个图表、表格和计算，我们都会向你展示自己复制它所需的确切代码。这就是为什么在本书中，很多时候你会看到一些代码后面紧跟着一张表格、一张图片或者是一些文字。如果你进入本书的网站，你会发现所有的代码，并且你可以尝试自己运行和修改每个例子。\n",
    "\n",
    "你刚刚看到了一个输出表格的单元格在书中的样子。下面是一个输出文本的单元格的例子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter会一直打印或显示最后一行的结果（如果有的话）。例如，这里是一个输出图像的单元格的例子：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=151x192>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = PILImage.create(image_cat())\n",
    "img.to_thumb(192)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 题外话结束\n",
    "\n",
    "那么，我们如何知道这个模型是否好呢？在表格的最后一栏，你可以看到错误率，也就是被错误识别的图像的比例。错误率是我们衡量模型质量的指标，应当是直观的且可理解的。正如你所看到的，这个模型几乎是完美的，尽管训练时间只有几秒钟（不包括一次性下载数据集和预训练的模型）。事实上，你所取得的准确度已经远远超过了任何人在10年前所取得的成绩\n",
    "\n",
    "最后，让我们检查一下这个模型是否真的有效。去找一张狗或猫的照片；如果你手头没有，就搜索谷歌图片，下载一张你在那里找到的图片。现在执行定义了uploader的单元格。它将输出一个你可以点击的按钮，所以你可以选择你想分类的图片：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d445286eb52f404ab59415087ca38f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "uploader = widgets.FileUpload()\n",
    "uploader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你可以把文件上传给模型。确保它是一张清晰的狗或猫的照片，而不是线描、卡通或类似的东西。notebook会告诉你是否它认为这是一只狗或一只猫，以及它的自信程度。希望你会发现，你的模型做得很好：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# For the book, we can't actually click an upload button, so we fake it\n",
    "uploader = SimpleNamespace(data=[\"../images/01.intro/chapter1_cat_example.jpg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a cat?: True.\n",
      "Probability it's a cat: 1.000000\n"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(uploader.data[0])\n",
    "is_cat, _, prob = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {prob[1].item():.6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "祝贺你的第一个分类器!\n",
    "\n",
    "但这是什么意思呢？你实际上做了什么？为了解释这个问题，让我们放大视角，以了解更多。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 什么是机器学习？\n",
    "\n",
    "你的分类器是一个深度学习模型。正如已经提到的，深度学习模型使用的是神经网络，它最初可以追溯到20世纪50年代，并且由于最近的进步而变得非常强大。\n",
    "\n",
    "另一个关键的背景是，深度学习只是机器学习这门更普遍的学科中的一个现代领域。要理解你在训练自己的分类模型时所做的事情的本质，你不需要理解深度学习。只要看到你的模型和你的训练过程是适用于一般机器学习的概念的例子，就足够了。\n",
    "\n",
    "因此在本节中，我们将描述什么是机器学习。我们将看一下关键的概念，并展示它们如何能被追溯到介绍它们的原始文章。\n",
    "\n",
    "机器学习和普通编程一样，是一种让计算机完成特定任务的方法。但是，我们如何使用常规编程来完成我们在上一节中所做的事情：识别照片中的狗和猫？我们将不得不为计算机写下完成任务所需的确切步骤。\n",
    "\n",
    "通常，我们在编写程序时，很容易写下完成一项任务的步骤。我们只需想一想，如果我们不得不亲自动手去做这项任务，我们会采取哪些步骤，然后把它们转化为代码。例如，我们可以写一个对列表进行排序的函数。一般来说，我们会写一个类似以下<<basic_program>>的函数（其中输入可能是一个未排序的列表，而结果是一个排序的列表）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stdout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: Path('dot'): Path('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 if mimetype in include}\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 if mimetype in include}\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa62c3b3610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption  A traditional program\n",
    "#is basic_program\n",
    "#alt Pipeline inputs, program, results\n",
    "gv(\"\"\"program[shape=box3d width=1 height=0.7]\n",
    "inputs->program->results\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但对于识别照片中的物体来说，这就有点棘手了；当我们识别照片中的物体时，我们会采取哪些步骤？我们真的不知道，因为这一切都发生在我们的大脑中，而我们却没有意识到这一点!\n",
    "\n",
    "回到计算刚刚兴起的时候，1949年，一位名叫阿瑟-塞缪尔（Arthur Samuel）的IBM研究员开始研究让计算机完成任务的不同方法，他称之为机器学习。他在1962年的经典文章《Artificial Intelligence: A Frontier of Automation》一文中写道：\n",
    "\n",
    "```\n",
    ": 为这种类计算任务编程是一项困难的任务，主要不是因为计算机本身有任何固有的复杂性，而是因为需要以最令人恼火的细节来说明这一过程的每一个细小步骤。正如任何程序员会告诉你的，计算机是巨大的白痴，而不是巨大的大脑。\n",
    "```\n",
    "\n",
    "他的基本想法是：不要告诉计算机解决一个问题所需的确切步骤，而是向它展示解决的问题的例子，让它自己想出如何解决问题。这被证明是非常有效的：到1961年，他的跳棋程序已经学到了很多东西，以至于它打败了康涅狄格州的冠军！以下是他对自己想法的描述（来自上述同一篇文章）：\n",
    "\n",
    "```\n",
    ": 假设我们安排一些自动手段来测试任何当前权重分配在实际性能方面的有效性，并提供一种机制来改变权重分配，以使性能最大化。我们不需要研究这种程序的细节，就可以看到它可以完全自动进行，并看到如此编程的机器将从其经验中“学习”。\n",
    "```\n",
    "这个简短的声明中蕴含着许多强有力的概念：\n",
    "- \"权重分配 \"的概念\n",
    "- 每个权重分配都有一些“实际性能”\n",
    "- 要求有一个测试该性能的“自动化方法”\n",
    "- 需要一个“机制”（即另一个自动程序），通过改变权重分配来提高性能\n",
    "\n",
    "让我们逐一讨论这些概念，以了解它们在实践中是如何结合的。首先，我们需要了解塞缪尔所说的权重分配是什么意思。\n",
    "\n",
    "权重只是变量，而权重分配是对这些变量数值的特定选择。程序的输入是它为了产生结果而处理的数值————例如，将图像像素作为输入，并将分类“狗”作为结果返回。程序的权重分配是定义程序如何运行的其他数值。\n",
    "\n",
    "由于它们会影响程序，在某种意义上它们是另一种输入，所以我们将更新<<basic_program>>中的基本图片，用<<weight_assignment>>来代替，以便考虑到这一点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stdout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: Path('dot'): Path('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 if mimetype in include}\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 if mimetype in include}\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa72d7c6bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption A program using weight assignment\n",
    "#id weight_assignment\n",
    "gv(\"\"\"model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results; weights->model\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经将我们图上的砖块的名字从程序改为模型。这是为了遵循现代术语，并反映出模型是一种特殊的程序：它是一个可以做许多不同事情的程序，这取决于权重。它可以用许多不同的方式来实现。例如，在塞缪尔的跳棋程序中，不同的权重值会导致不同的跳棋游戏策略。\n",
    "\n",
    "（顺便说一下，塞缪尔所说的“权重”现在一般被称为模型参数，如果你遇到过这个词的话。权重一词则作为一种特殊类型的模型参数而保留下来）。\n",
    "\n",
    "接下来，塞缪尔说，我们需要一种自动化方法来测试任何当前权重分配在实际性能方面的有效性。在他的跳棋程序中，一个模型的 \"实际表现 \"就是它的棋艺如何。你可以自动测试两个模型的性能，将它们设置为相互对弈，看看哪一个通常会赢。\n",
    "\n",
    "最后，他说我们需要一个改变权重分配的机制，以使性能最大化。例如，我们可以看一下获胜模型和失败模型之间的权重差异，然后在获胜的方向上再调整一下权重。\n",
    "\n",
    "我们现在可以看到，为什么他说这样的程序可以完全自动化，而且......如此编程的机器将从其经验中“学习”。当权重的调整也是自动的时候，学习就会变得完全自动————当我们不是通过手动调整权重来改善一个模型，而是依靠一个自动机制，根据性能进行调整。\n",
    "\n",
    "<<training_loop>>显示了塞缪尔训练机器学习模型的想法的全貌。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no layout engine support for \"dot\"\n",
      "Perhaps \"dot -c\" needs to be run (with installer's privileges) to register the plugins?\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1. [stderr: 'There is no layout engine support for \"dot\"\\nPerhaps \"dot -c\" needs to be run (with installer\\'s privileges) to register the plugins?\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m             raise CalledProcessError(self.returncode, self.args, self.stdout,\n\u001b[0;32m--> 444\u001b[0;31m                                      self.stderr)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 if mimetype in include}\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 if mimetype in include}\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1. [stderr: 'There is no layout engine support for \"dot\"\\nPerhaps \"dot -c\" needs to be run (with installer\\'s privileges) to register the plugins?\\n']"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fdd05348550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Training a machine learning model\n",
    "#id training_loop\n",
    "#alt The basic training loop\n",
    "gv(\"\"\"ordering=in\n",
    "model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results; weight->model; results->performance\n",
    "performance->weights[constraint=false label=update]\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意模型的结果（例如跳棋游戏中的棋子）和它的性能（例如它是否赢得游戏，或者它赢得多快）之间的区别。\n",
    "\n",
    "还要注意的是，一旦模型训练完成，也就是说，一旦我们选择了最终的、最好的、最具希望的权重分配，那么我们就可以把权重看作是模型的一部分，因为我们不再改变它们了。\n",
    "\n",
    "因此，在一个模型训练完成后，实际使用该模型看起来像<<using_model>>。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There is no layout engine support for \"dot\"\n",
      "Perhaps \"dot -c\" needs to be run (with installer's privileges) to register the plugins?\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1. [stderr: 'There is no layout engine support for \"dot\"\\nPerhaps \"dot -c\" needs to be run (with installer\\'s privileges) to register the plugins?\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m             raise CalledProcessError(self.returncode, self.args, self.stdout,\n\u001b[0;32m--> 444\u001b[0;31m                                      self.stderr)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 if mimetype in include}\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 if mimetype in include}\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '[Path('dot'), '-Kdot', '-Tsvg']' returned non-zero exit status 1. [stderr: 'There is no layout engine support for \"dot\"\\nPerhaps \"dot -c\" needs to be run (with installer\\'s privileges) to register the plugins?\\n']"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fdd06050910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Using a trained model as a program\n",
    "#id using_model\n",
    "gv('''model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这看起来与我们在<<basic_program>>中的原图完全一样，只是把程序这个词换成了模型。这是一个重要的见解：一个经过训练的模型可以像一个普通的计算机程序一样被对待。\n",
    "\n",
    "```\n",
    "术语：机器学习：通过让计算机从其经验中学习，而不是通过手动编码各个步骤来开发程序的训练。\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 什么是神经网络？\n",
    "\n",
    "不难想象，跳棋程序的模型可能是什么样子的。可能会有一系列的跳棋策略被编码，还有某种搜索机制，然后权重可以改变策略的选择方式，在搜索过程中关注棋盘的哪些部分，等等。但是，对于图像识别程序，或者对于理解文本，或者对于我们可能想象的许多其他有趣的问题，这个模型可能是什么样子的，一点也不明显。\n",
    "\n",
    "我们想要的是某种函数，它非常灵活，只需改变其权重，就可以用来解决任何给定的问题。令人惊讶的是，这种函数实际上是存在的！它就是我们已经讨论过的神经网络。也就是说，如果你把神经网络看作是一个数学函数，那么它就变成了一个根据其权重而极其灵活的函数。一个被称为普遍近似定理的数学证明表明，从理论上讲，这个函数可以以任何精度解决任何问题。实际上，神经网络如此灵活意味着，在实践中，它们往往是一种合适的模型，你可以把精力集中在训练它们的过程中，也就是找到最佳的权重分配。\n",
    "\n",
    "但这个过程是怎样的呢？我们可以想象，你可能需要找到一个新的“机制”来自动为每个问题更新权重。这将是很费力的。我们在这里也希望有一种完全通用的方法来更新神经网络的权重，以使它在任何给定的任务中得到提升。方便的是，这一方法也是存在的！\n",
    "\n",
    "这被称为随机梯度下降（SGD）。我们将在<<chapter_mnist_basics>>中详细了解神经网络和SGD的工作原理，以及解释通用近似定理。不过现在，我们将改用塞缪尔自己的话： 我们不需要深入了解这种程序的细节，就可以看到它可以完全自动化，并看到如此编程的机器将从其经验中“学习”。\n",
    "\n",
    "```\n",
    "J：别担心，SGD和神经网络在数学上都不复杂。两者都几乎完全依靠加法和乘法来完成它们的工作（但它们做了大量的加法和乘法！）。当学生们看到这些细节时，我们听到的主要反应是：“这就是它的全部吗？”\n",
    "```\n",
    "换句话说，概括地说，神经网络是一种特殊的机器学习模型，它正好符合塞缪尔的原始概念。神经网络很特别，因为它们高度灵活，这意味着它们可以通过找到正确的权重来解决异常广泛的问题。这很强大，因为随机梯度下降为我们提供了一种自动寻找这些权重值的方法。\n",
    "\n",
    "现在让我们继续放大视角，用Samuel的框架重新审视我们的图像分类问题。\n",
    "\n",
    "我们的输入是图像。我们的权重是神经网中的权重。我们的模型是一个神经网络。我们的结果是由神经网络计算出来的值，如“狗”或“猫”。\n",
    "\n",
    "那么，下一个部分，即以实际表现来测试任何当前权重分配的有效性的自动化方法呢？确定“实际表现”是很容易的：我们可以简单地将我们的模型的表现定义为预测正确答案的准确性。\n",
    "\n",
    "把这一切放在一起，并假设SGD是我们更新权重分配的机制，我们可以看到我们的图像分类器是一个机器学习模型，很像塞缪尔设想的那样。\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习的一些术语\n",
    "\n",
    "塞缪尔工作在20世纪60年代，从那时起，术语已经改变了。以下是我们讨论过的所有作品中使用的现代深度学习术语：\n",
    "\n",
    "- 模型的功能形式被称为其架构（但要小心————有时人们把模型作为架构的同义词，所以这可能会引起混淆）。\n",
    "- 这些权重被称为参数。\n",
    "- 预测值是根据自变量计算的，自变量是不包括标签的数据。\n",
    "- 该模型的结果被称为预测值。\n",
    "- 衡量性能的标准称为损失。\n",
    "- 损失不仅取决于预测，而且还取决于正确的标签（也称为目标或因变量），例如，“狗”或“猫”。\n",
    "\n",
    "做了这些改动后，我们在<<training_loop>>中的图看起来像<<detailed_loop>>。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stdout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: Path('dot'): Path('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 if mimetype in include}\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 if mimetype in include}\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                               category=category)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                                  encoding=encoding)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute Path('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.sources.Source at 0x7fa72d7e3750>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Detailed training loop\n",
    "#id detailed_loop\n",
    "gv('''ordering=in\n",
    "model[shape=box3d width=1 height=0.7 label=architecture]\n",
    "inputs->model->predictions; parameters->model; labels->loss; predictions->loss\n",
    "loss->parameters[constraint=false label=update]''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习固有的局限\n",
    "\n",
    "从这幅图中，我们现在可以看到关于训练深度学习模型的一些基本情况：\n",
    "\n",
    "- 没有数据就无法创建模型。\n",
    "- 一个模型只能学会以在训练它的输入数据中能看见的模式工作\n",
    "- 这种学习方法只创造预测，而不是推荐行动。\n",
    "- 仅仅有输入数据的例子是不够的；我们还需要为这些数据贴上标签（例如，狗和猫的图片不足以训练一个模型；我们还需要为每张图片贴上标签，说明哪些是狗，哪些是猫）。\n",
    "\n",
    "一般来说，我们看到，大多数组织说他们没有足够的数据，实际上是指他们没有足够的标记数据。如果任何组织有兴趣在实践中用一个模型做一些事情，那么他们可能有一些输入，他们计划针对这些模型运行。而且，他们可能已经用其他方式做了一段时间（例如，手动或用一些启发式程序），所以他们有来自这些过程的数据！例如，一个放射科诊所几乎肯定会有一个医疗扫描档案（因为他们需要能够检查他们的病人在一段时间内的进展情况），但这些扫描可能没有包含诊断或干预措施清单的结构化标签（因为放射科医生通常创建自由文本自然语言报告，而不是结构化数据）。我们将在本书中大量讨论标签方法，因为它是实践中的一个重要问题。\n",
    "\n",
    "由于这类机器学习模型只能进行预测（即试图复制标签），这可能导致组织目标和模型能力之间的巨大差距。例如，在本书中，你将学习如何创建一个能够预测用户可能购买的产品的推荐系统。这通常用于电子商务中，比如通过显示排名最高的商品来定制显示在主页上的产品。但这样的模型一般是通过查看用户和他们的购买历史（输入）以及他们继续购买或看的东西（标签）来创建的，这意味着该模型可能会告诉你用户已经拥有或已经知道的产品，而不是他们最有可能感兴趣的新产品。这与比如说，你当地书商的专家可能做的非常不同，他们会问一些问题来了解你的品味，然后告诉你一些你以前从未听说过的作家或系列。\n",
    "\n",
    "由于这类机器学习模型只能进行预测（即试图复制标签），可能导致组织目标和模型能力之间的巨大差距。例如，在本书中，你将学习如何创建一个能够预测用户可能购买的产品的推荐系统。这通常用于电子商务中，比如通过在主页上定制显示排名最高的商品。但这样的模型一般是通过查看用户和他们的购买历史（输入）以及他们继续购买或看的东西（标签）来创建的，这意味着该模型可能会告诉你用户已经拥有或已经知道的产品，而不是他们最有可能感兴趣的新产品。这与当地书商的专家可能会做的非常不同，他们会问问题来了解你的品味，然后告诉你以前从未听说过的作者或系列。\n",
    "\n",
    "另一个关键的见解来自于考虑一个模型如何与环境互动。这可以创造反馈回路，如这里所描述的：\n",
    "- 根据过去的逮捕地点，建立了一个预测警务模型。在实践中，这实际上不是在预测犯罪，而是在预测逮捕，因此这部分只是反映了现有警务程序的偏好。\n",
    "- 然后，执法人员可能会使用该模型来决定将他们的警察活动集中在哪里，从而在这些地区增加逮捕人数。\n",
    "\n",
    "这是一个正反馈循环，模型用得越多，数据就越偏，使模型更加偏，以此类推。\n",
    "\n",
    "反馈循环也会在商业环境中产生问题。例如，一个视频推荐系统可能会偏向于推荐视频的最大观看者所消费的内容（例如，阴谋论者和极端主义者往往比一般人观看更多的在线视频内容），导致这类用户的视频消费增加，从而导致更多的这类视频被推荐。我们将在<<chapter_ethics>>中更详细地考虑这个话题。\n",
    "\n",
    "现在你已经看到了基础的理论，让我们回到我们的样例代码，详细看看代码是如何与我们刚才描述的过程相对应的。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我们的图像识别器是如何工作的？\n",
    "\n",
    "让我们来看看我们的图像识别器代码是如何与这些想法对应的。我们将把每一行放到一个单独的单元格中，看看每一行在做什么（我们不会解释每一个参数的每一个细节，但会给出一个重要部分的描述；完整的细节将在本书后面出现）。\n",
    "\n",
    "第一行导入fastai.vision库的所有内容。\n",
    "```python\n",
    "from fastai.vision.all import *\n",
    "```\n",
    "这为我们提供了创建各种计算机视觉模型所需的所有函数和类。\n",
    "\n",
    "```\n",
    "J: 很多Python编码人员建议避免像这样导入整个库（使用import * 语法），因为在大型软件项目中，这可能会导致问题。然而，对于交互式工作，比如在Jupyter笔记本中，它非常好用。fastai库是专门为支持这种交互式使用而设计的，它只将必要的部分导入你的环境中。\n",
    "```\n",
    "\n",
    "第二行从fast.ai的数据集中下载一个标准数据集（如果之前没有下载）到你的服务器，提取它（如果之前没有提取），并返回一个带有提取位置的Path对象：\n",
    "```python\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "```\n",
    "S: 在fast.ai学习的这段时间里，甚至到现在，我都学到了很多关于高效编码的做法。fastai库和fast.ai的笔记本上有很多很棒的小提示，帮助我成为一个更好的程序员。例如，注意到fastai库并不只是返回一个包含数据集路径的字符串，而是一个Path对象。这是Python 3标准库中一个非常有用的类，它使访问文件和目录变得更加容易。如果你以前没有接触过它，一定要看看它的文档或教程，并尝试一下。请注意，https://book.fast.ai 包含每一章的推荐教程的链接。我将继续让你知道我发现的有用的编码小技巧。\n",
    "\n",
    "在第三行，我们定义了一个函数is_cat，它根据数据集创建者提供的文件名规则给猫贴上标签：\n",
    "```python\n",
    "def is_cat(x): return x[0].isupper()\n",
    "```\n",
    "我们在第四行使用该函数，它告诉fastai我们有什么样的数据集以及它的结构：\n",
    "```python\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "```\n",
    "对于不同类型的深度学习数据集和问题，有各种不同的数据类型————这里我们使用ImageDataLoaders。类名的第一部分一般是你所拥有的数据类型，如图像，或文本。\n",
    "\n",
    "我们必须告诉fastai的另一个重要信息是如何从数据集中获得标签。计算机视觉数据集的结构通常是这样的：图像的标签是文件名或路径的一部分，最常见的是父文件夹名称。这里我们要告诉fastai使用我们刚刚定义的is_cat函数。\n",
    "\n",
    "最后，我们定义我们需要的Transform。Transform包含在训练中自动应用的代码；fastai包括许多预定义的Transform，添加新的Transform就像创建一个Python函数一样简单。有两种类型的Transform： item_tfms应用于每个项目（在本例中，每个项目被调整为224像素的正方形），而batch_tfms使用GPU一次应用于一批项目，所以它们特别快（我们将在本书中看到许多这样的例子）。\n",
    "\n",
    "为什么是224像素？由于历史原因，这是标准尺寸（旧的预训练模型正好需要这个尺寸），但你几乎可以通过任何尺寸。如果你增加尺寸，你通常会得到一个结果更好的模型（因为它将能够专注于更多的细节），但代价是速度和内存消耗；如果你减少尺寸，则相反。\n",
    "\n",
    "```\n",
    "注：分类和回归：分类和回归在机器学习中具有非常具体的含义。这是我们将在本书中研究的两种主要的模型类型。分类模型用于尝试预测分类，或类别。也就是说，它是从一些离散的可能性中进行预测的，比如 \"狗 \"或 \"猫\"。回归模型尝试预测一个或多个数字，如温度或位置。有时，人们用回归这个词来指称一种特殊的模型，称为线性回归模型；这是一种不好的做法，我们在本书中不会使用这个术语！\n",
    "```\n",
    "\n",
    "宠物数据集包含7390张狗和猫的图片，共计37个不同品种。每张图片都用其文件名进行标注：例如，文件great_pyrenees_173.jpg是数据集中第173张大白熊犬的图片。如果图像是一只猫，文件名就以大写字母开头，否则就以小写字母开头。我们必须告诉fastai如何从文件名中获取标签，我们通过调用from_name_func（这意味着可以使用应用于文件名的函数来提取标签），并传递is_cat，它返回x[0].isupper()，如果第一个字母是大写的（即，它是一只猫），则评估为真。\n",
    "\n",
    "这里要提到的最重要的参数是valid_pct=0.2。这告诉fastai保留20%的数据，这部分数据完全不用于训练模型。这20%的数据被称为验证集；其余80%的数据被称为训练集。验证集是用来衡量模型的准确性的。默认情况下，被保留的20%的数据是随机选择的。seed=42这个参数在我们每次运行这段代码时都将随机种子设置为相同的值，这意味着我们每次运行都会得到相同的验证集————这样，如果我们改变模型并重新训练它，我们知道任何差异都是由于模型的变化造成的，而不是由于拥有不同的随机验证集。\n",
    "\n",
    "fastai会一直显示你的模型的准确性，准确性的计算只使用验证集，而不是训练集。这一点绝对是至关重要的，因为如果你训练一个足够大的模型，训练时间足够长，它最终会记住你的数据集中的每一个数据的标签！结果我们获得了一个没有用的模型，因为我们关心的是我们的模型在以前未见过的图像上的效果如何。这始终是我们在创建模型时的目标：让它在经过训练后，在未来才会看到的数据上发挥作用。\n",
    "\n",
    "即使你的模型没有完全记住你的所有数据，在训练的早期，它可能已经记住了其中的某些部分。因此，你训练的时间越长，你在训练集上的准确率就越高；验证集的准确率也会提高一段时间，但最终会开始变差，因为模型开始记忆训练集，而不是在数据中找到可归纳的基本模式。当这种情况发生时，我们说模型是过拟合的。\n",
    "\n",
    "<<img_overfit>>显示了过度拟合时的情况，使用一个简化的例子，例子中只有一个参数，以及一些基于函数$x^2$随机生成的数据。正如你所看到的，尽管过度拟合模型中的预测对于靠近观察到的数据点的数据是准确的，但当超出这个范围时，它们就会有很大的偏差。\n",
    "\n",
    "Example of overfitting\n",
    "Overfitting is the single most important and challenging issue when training for all machine learning practitioners, and all algorithms. As you will see, it is very easy to create a model that does a great job at making predictions on the exact data it has been trained on, but it is much harder to make accurate predictions on data the model has never seen before. And of course, this is the data that will actually matter in practice. For instance, if you create a handwritten digit classifier (as we will very soon!) and use it to recognize numbers written on checks, then you are never going to see any of the numbers that the model was trained on—checks will have slightly different variations of writing to deal with. You will learn many methods to avoid overfitting in this book. However, you should only use those methods after you have confirmed that overfitting is actually occurring (i.e., you have actually observed the validation accuracy getting worse during training). We often see practitioners using over-fitting avoidance techniques even when they have enough data that they didn't need to do so, ending up with a model that may be less accurate than what they could have achieved.\n",
    "\n",
    "important: Validation Set: When you train a model, you must always have both a training set and a validation set, and must measure the accuracy of your model only on the validation set. If you train for too long, with not enough data, you will see the accuracy of your model start to get worse; this is called overfitting. fastai defaults valid_pct to 0.2, so even if you forget, fastai will create a validation set for you!\n",
    "\n",
    "The fifth line of the code training our image recognizer tells fastai to create a convolutional neural network (CNN) and specifies what architecture to use (i.e. what kind of model to create), what data we want to train it on, and what metric to use:\n",
    "\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "Why a CNN? It's the current state-of-the-art approach to creating computer vision models. We'll be learning all about how CNNs work in this book. Their structure is inspired by how the human vision system works.\n",
    "\n",
    "There are many different architectures in fastai, which we will introduce in this book (as well as discussing how to create your own). Most of the time, however, picking an architecture isn't a very important part of the deep learning process. It's something that academics love to talk about, but in practice it is unlikely to be something you need to spend much time on. There are some standard architectures that work most of the time, and in this case we're using one called ResNet that we'll be talking a lot about during the book; it is both fast and accurate for many datasets and problems. The 34 in resnet34 refers to the number of layers in this variant of the architecture (other options are 18, 50, 101, and 152). Models using architectures with more layers take longer to train, and are more prone to overfitting (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse). On the other hand, when using more data, they can be quite a bit more accurate.\n",
    "\n",
    "What is a metric? A metric is a function that measures the quality of the model's predictions using the validation set, and will be printed at the end of each epoch. In this case, we're using error_rate, which is a function provided by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is accuracy (which is just 1.0 - error_rate). fastai provides many more, which will be discussed throughout this book.\n",
    "\n",
    "The concept of a metric may remind you of loss, but there is an important distinction. The entire purpose of loss is to define a \"measure of performance\" that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case.\n",
    "\n",
    "vision_learner also has a parameter pretrained, which defaults to True (so it's used in this case, even though we haven't specified it), which sets the weights in your model to values that have already been trained by experts to recognize a thousand different categories across 1.3 million photos (using the famous ImageNet dataset). A model that has weights that have already been trained on some other dataset is called a pretrained model. You should nearly always use a pretrained model, because it means that your model, before you've even shown it any of your data, is already very capable. And, as you'll see, in a deep learning model many of these capabilities are things you'll need, almost regardless of the details of your project. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks.\n",
    "\n",
    "When using a pretrained model, vision_learner will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the head.\n",
    "\n",
    "Using pretrained models is the most important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money. You might think that would mean that using pretrained models would be the most studied area in academic deep learning... but you'd be very, very wrong! The importance of pretrained models is generally not recognized or discussed in most courses, books, or software library features, and is rarely considered in academic papers. As we write this at the start of 2020, things are just starting to change, but it's likely to take a while. So be careful: most people you speak to will probably greatly underestimate what you can do in deep learning with few resources, because they probably won't deeply understand how to use pretrained models.\n",
    "\n",
    "Using a pretrained model for a task different to what it was originally trained for is known as transfer learning. Unfortunately, because transfer learning is so under-studied, few domains have pretrained models available. For instance, there are currently few pretrained models available in medicine, making transfer learning challenging to use in that domain. In addition, it is not yet well understood how to use transfer learning for tasks such as time series analysis.\n",
    "\n",
    "jargon: Transfer learning: Using a pretrained model for a task different to what it was originally trained for.\n",
    "\n",
    "The sixth line of our code tells fastai how to fit the model:\n",
    "\n",
    "learn.fine_tune(1)\n",
    "As we've discussed, the architecture only describes a template for a mathematical function; it doesn't actually do anything until we provide values for the millions of parameters it contains.\n",
    "\n",
    "This is the key to deep learning—determining how to fit the parameters of a model to get it to solve your problem. In order to fit a model, we have to provide at least one piece of information: how many times to look at each image (known as number of epochs). The number of epochs you select will largely depend on how much time you have available, and how long you find it takes in practice to fit your model. If you select a number that is too small, you can always train for more epochs later.\n",
    "\n",
    "But why is the method called fine_tune, and not fit? fastai actually does have a method called fit, which does indeed fit a model (i.e. look at images in the training set multiple times, each time updating the parameters to make the predictions closer and closer to the target labels). But in this case, we've started with a pretrained model, and we don't want to throw away all those capabilities that it already has. As you'll learn in this book, there are some important tricks to adapt a pretrained model for a new dataset—a process called fine-tuning.\n",
    "\n",
    "jargon: Fine-tuning: A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining.\n",
    "\n",
    "When you use the fine_tune method, fastai will use these tricks for you. There are a few parameters you can set (which we'll discuss later), but in the default form shown here, it does two steps:\n",
    "\n",
    "Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with your dataset.\n",
    "Use the number of epochs requested when calling the method to fit the entire model, updating the weights of the later layers (especially the head) faster than the earlier layers (which, as we'll see, generally don't require many changes from the pretrained weights).\n",
    "The head of a model is the part that is newly added to be specific to the new dataset. An epoch is one complete pass through the dataset. After calling fit, the results after each epoch are printed, showing the epoch number, the training and validation set losses (the \"measure of performance\" used for training the model), and any metrics you've requested (error rate, in this case).\n",
    "\n",
    "So, with all this code our model learned to recognize cats and dogs just from labeled examples. But how did it do it?\n",
    "\n",
    "What Our Image Recognizer Learned\n",
    "At this stage we have an image recognizer that is working very well, but we have no idea what it is actually doing! Although many people complain that deep learning results in impenetrable \"black box\" models (that is, something that gives predictions but that no one can understand), this really couldn't be further from the truth. There is a vast body of research showing how to deeply inspect deep learning models, and get rich insights from them. Having said that, all kinds of machine learning models (including deep learning, and traditional statistical models) can be challenging to fully understand, especially when considering how they will behave when coming across data that is very different to the data used to train them. We'll be discussing this issue throughout this book.\n",
    "\n",
    "In 2013 a PhD student, Matt Zeiler, and his supervisor, Rob Fergus, published the paper \"Visualizing and Understanding Convolutional Networks\", which showed how to visualize the neural network weights learned in each layer of a model. They carefully analyzed the model that won the 2012 ImageNet competition, and used this analysis to greatly improve the model, such that they were able to go on to win the 2013 competition! <<img_layer1>> is the picture that they published of the first layer's weights.\n",
    "\n",
    "Activations of the first layer of a CNN\n",
    "This picture requires some explanation. For each layer, the image part with the light gray background shows the reconstructed weights pictures, and the larger section at the bottom shows the parts of the training images that most strongly matched each set of weights. For layer 1, what we can see is that the model has discovered weights that represent diagonal, horizontal, and vertical edges, as well as various different gradients. (Note that for each layer only a subset of the features are shown; in practice there are thousands across all of the layers.) These are the basic building blocks that the model has learned for computer vision. They have been widely analyzed by neuroscientists and computer vision researchers, and it turns out that these learned building blocks are very similar to the basic visual machinery in the human eye, as well as the handcrafted computer vision features that were developed prior to the days of deep learning. The next layer is represented in <<img_layer2>>.\n",
    "\n",
    "Activations of the second layer of a CNN\n",
    "For layer 2, there are nine examples of weight reconstructions for each of the features found by the model. We can see that the model has learned to create feature detectors that look for corners, repeating lines, circles, and other simple patterns. These are built from the basic building blocks developed in the first layer. For each of these, the right-hand side of the picture shows small patches from actual images which these features most closely match. For instance, the particular pattern in row 2, column 1 matches the gradients and textures associated with sunsets.\n",
    "\n",
    "<<img_layer3>> shows the image from the paper showing the results of reconstructing the features of layer 3.\n",
    "\n",
    "Activations of the third layer of a CNN\n",
    "As you can see by looking at the righthand side of this picture, the features are now able to identify and match with higher-level semantic components, such as car wheels, text, and flower petals. Using these components, layers four and five can identify even higher-level concepts, as shown in <<img_layer4>>.\n",
    "\n",
    "Activations of layers 4 and 5 of a CNN\n",
    "This article was studying an older model called AlexNet that only contained five layers. Networks developed since then can have hundreds of layers—so you can imagine how rich the features developed by these models can be!\n",
    "\n",
    "When we fine-tuned our pretrained model earlier, we adapted what those last layers focus on (flowers, humans, animals) to specialize on the cats versus dogs problem. More generally, we could specialize such a pretrained model on many different tasks. Let's have a look at some examples.\n",
    "\n",
    "Image Recognizers Can Tackle Non-Image Tasks\n",
    "An image recognizer can, as its name suggests, only recognize images. But a lot of things can be represented as images, which means that an image recogniser can learn to complete many tasks.\n",
    "\n",
    "For instance, a sound can be converted to a spectrogram, which is a chart that shows the amount of each frequency at each time in an audio file. Fast.ai student Ethan Sutin used this approach to easily beat the published accuracy of a state-of-the-art environmental sound detection model using a dataset of 8,732 urban sounds. fastai's show_batch clearly shows how each different sound has a quite distinctive spectrogram, as you can see in <<img_spect>>.\n",
    "\n",
    "show_batch with spectrograms of sounds\n",
    "A time series can easily be converted into an image by simply plotting the time series on a graph. However, it is often a good idea to try to represent your data in a way that makes it as easy as possible to pull out the most important components. In a time series, things like seasonality and anomalies are most likely to be of interest. There are various transformations available for time series data. For instance, fast.ai student Ignacio Oguiza created images from a time series dataset for olive oil classification, using a technique called Gramian Angular Difference Field (GADF); you can see the result in <<ts_image>>. He then fed those images to an image classification model just like the one you see in this chapter. His results, despite having only 30 training set images, were well over 90% accurate, and close to the state of the art.\n",
    "\n",
    "Converting a time series into an image\n",
    "Another interesting fast.ai student project example comes from Gleb Esman. He was working on fraud detection at Splunk, using a dataset of users' mouse movements and mouse clicks. He turned these into pictures by drawing an image where the position, speed, and acceleration of the mouse pointer was displayed using coloured lines, and the clicks were displayed using small colored circles, as shown in <>. He then fed this into an image recognition model just like the one we've used in this chapter, and it worked so well that it led to a patent for this approach to fraud analytics!\n",
    "\n",
    "Converting computer mouse behavior to an image\n",
    "Another example comes from the paper \"Malware Classification with Deep Convolutional Neural Networks\" by Mahmoud Kalash et al., which explains that \"the malware binary file is divided into 8-bit sequences which are then converted to equivalent decimal values. This decimal vector is reshaped and a gray-scale image is generated that represents the malware sample,\" like in <<malware_proc>>.\n",
    "\n",
    "Malware classification process\n",
    "The authors then show \"pictures\" generated through this process of malware in different categories, as shown in <<malware_eg>>.\n",
    "\n",
    "Malware examples\n",
    "As you can see, the different types of malware look very distinctive to the human eye. The model the researchers trained based on this image representation was more accurate at malware classification than any previous approach shown in the academic literature. This suggests a good rule of thumb for converting a dataset into an image representation: if the human eye can recognize categories from the images, then a deep learning model should be able to do so too.\n",
    "\n",
    "In general, you'll find that a small number of general approaches in deep learning can go a long way, if you're a bit creative in how you represent your data! You shouldn't think of approaches like the ones described here as \"hacky workarounds,\" because actually they often (as here) beat previously state-of-the-art results. These really are the right ways to think about these problem domains.\n",
    "\n",
    "Jargon Recap\n",
    "We just covered a lot of information so let's recap briefly, <> provides a handy vocabulary.\n",
    "\n",
    "asciidoc\n",
    "[[dljargon]]\n",
    ".Deep learning vocabulary\n",
    "[options=\"header\"]\n",
    "|=====\n",
    "| Term | Meaning\n",
    "|Label | The data that we're trying to predict, such as \"dog\" or \"cat\"\n",
    "|Architecture | The _template_ of the model that we're trying to fit; the actual mathematical function that we're passing the input data and parameters to\n",
    "|Model | The combination of the architecture with a particular set of parameters\n",
    "|Parameters | The values in the model that change what task it can do, and are updated through model training\n",
    "|Fit | Update the parameters of the model such that the predictions of the model using the input data match the target labels\n",
    "|Train | A synonym for _fit_\n",
    "|Pretrained model | A model that has already been trained, generally using a large dataset, and will be fine-tuned\n",
    "|Fine-tune | Update a pretrained model for a different task\n",
    "|Epoch | One complete pass through the input data\n",
    "|Loss | A measure of how good the model is, chosen to drive training via SGD\n",
    "|Metric | A measurement of how good the model is, using the validation set, chosen for human consumption\n",
    "|Validation set | A set of data held out from training, used only for measuring how good the model is\n",
    "|Training set | The data used for fitting the model; does not include any data from the validation set\n",
    "|Overfitting | Training a model in such a way that it _remembers_ specific features of the input data, rather than generalizing well to data not seen during training\n",
    "|CNN | Convolutional neural network; a type of neural network that works particularly well for computer vision tasks\n",
    "|=====\n",
    "With this vocabulary in hand, we are now in a position to bring together all the key concepts introduced so far. Take a moment to review those definitions and read the following summary. If you can follow the explanation, then you're well equipped to understand the discussions to come.\n",
    "\n",
    "Machine learning is a discipline where we define a program not by writing it entirely ourselves, but by learning from data. Deep learning is a specialty within machine learning that uses neural networks with multiple layers. Image classification is a representative example (also known as image recognition). We start with labeled data; that is, a set of images where we have assigned a label to each image indicating what it represents. Our goal is to produce a program, called a model, which, given a new image, will make an accurate prediction regarding what that new image represents.\n",
    "\n",
    "Every model starts with a choice of architecture, a general template for how that kind of model works internally. The process of training (or fitting) the model is the process of finding a set of parameter values (or weights) that specialize that general architecture into a model that works well for our particular kind of data. In order to define how well a model does on a single prediction, we need to define a loss function, which determines how we score a prediction as good or bad.\n",
    "\n",
    "To make the training process go faster, we might start with a pretrained model—a model that has already been trained on someone else's data. We can then adapt it to our data by training it a bit more on our data, a process called fine-tuning.\n",
    "\n",
    "When we train a model, a key concern is to ensure that our model generalizes—that is, that it learns general lessons from our data which also apply to new items it will encounter, so that it can make good predictions on those items. The risk is that if we train our model badly, instead of learning general lessons it effectively memorizes what it has already seen, and then it will make poor predictions about new images. Such a failure is called overfitting. In order to avoid this, we always divide our data into two parts, the training set and the validation set. We train the model by showing it only the training set and then we evaluate how well the model is doing by seeing how well it performs on items from the validation set. In this way, we check if the lessons the model learns from the training set are lessons that generalize to the validation set. In order for a person to assess how well the model is doing on the validation set overall, we define a metric. During the training process, when the model has seen every item in the training set, we call that an epoch.\n",
    "\n",
    "All these concepts apply to machine learning in general. That is, they apply to all sorts of schemes for defining a model by training it with data. What makes deep learning distinctive is a particular class of architectures: the architectures based on neural networks. In particular, tasks like image classification rely heavily on convolutional neural networks, which we will discuss shortly.\n",
    "\n",
    "Deep Learning Is Not Just for Image Classification\n",
    "Deep learning's effectiveness for classifying images has been widely discussed in recent years, even showing superhuman results on complex tasks like recognizing malignant tumors in CT scans. But it can do a lot more than this, as we will show here.\n",
    "\n",
    "For instance, let's talk about something that is critically important for autonomous vehicles: localizing objects in a picture. If a self-driving car doesn't know where a pedestrian is, then it doesn't know how to avoid one! Creating a model that can recognize the content of every individual pixel in an image is called segmentation. Here is how we can train a segmentation model with fastai, using a subset of the Camvid dataset from the paper \"Semantic Object Classes in Video: A High-Definition Ground Truth Database\" by Gabruel J. Brostow, Julien Fauqueur, and Roberto Cipolla:\n",
    "\n",
    "\n",
    "path = untar_data(URLs.CAMVID_TINY)\n",
    "dls = SegmentationDataLoaders.from_label_func(\n",
    "    path, bs=8, fnames = get_image_files(path/\"images\"),\n",
    "    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "    codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    ")\n",
    "\n",
    "learn = unet_learner(dls, resnet34)\n",
    "learn.fine_tune(8)\n",
    "     \n",
    "epoch\ttrain_loss\tvalid_loss\ttime\n",
    "0\t2.641862\t2.140568\t00:02\n",
    "epoch\ttrain_loss\tvalid_loss\ttime\n",
    "0\t1.624964\t1.464210\t00:02\n",
    "1\t1.454148\t1.284032\t00:02\n",
    "2\t1.342955\t1.048562\t00:02\n",
    "3\t1.199765\t0.852787\t00:02\n",
    "4\t1.078090\t0.838206\t00:02\n",
    "5\t0.975496\t0.746806\t00:02\n",
    "6\t0.892793\t0.725384\t00:02\n",
    "7\t0.827645\t0.726778\t00:02\n",
    "We are not even going to walk through this code line by line, because it is nearly identical to our previous example! (Although we will be doing a deep dive into segmentation models in <<chapter_arch_details>>, along with all of the other models that we are briefly introducing in this chapter, and many, many more.)\n",
    "\n",
    "We can visualize how well it achieved its task, by asking the model to color-code each pixel of an image. As you can see, it nearly perfectly classifies every pixel in every object. For instance, notice that all of the cars are overlaid with the same color and all of the trees are overlaid with the same color (in each pair of images, the lefthand image is the ground truth label and the right is the prediction from the model):\n",
    "\n",
    "\n",
    "learn.show_results(max_n=6, figsize=(7,8))\n",
    "     \n",
    "\n",
    "One other area where deep learning has dramatically improved in the last couple of years is natural language processing (NLP). Computers can now generate text, translate automatically from one language to another, analyze comments, label words in sentences, and much more. Here is all of the code necessary to train a model that can classify the sentiment of a movie review better than anything that existed in the world just five years ago:\n",
    "\n",
    "\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)\n",
    "     \n",
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.878776\t0.748753\t0.500400\t01:27\n",
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.679118\t0.674778\t0.584040\t02:45\n",
    "1\t0.653671\t0.670396\t0.618040\t02:55\n",
    "2\t0.598665\t0.551815\t0.718920\t05:28\n",
    "3\t0.556812\t0.507450\t0.752480\t03:11\n",
    "clean\n",
    "If you hit a \"CUDA out of memory error\" after running this cell, click on the menu Kernel, then restart. Instead of executing the cell above, copy and paste the following code in it:\n",
    "\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)\n",
    "This reduces the batch size to 32 (we will explain this later). If you keep hitting the same error, change 32 to 16.\n",
    "\n",
    "This model is using the \"IMDb Large Movie Review dataset\" from the paper \"Learning Word Vectors for Sentiment Analysis\" by Andrew Maas et al. It works well with movie reviews of many thousands of words, but let's test it out on a very short one to see how it does its thing:\n",
    "\n",
    "\n",
    "learn.predict(\"I really liked that movie!\")\n",
    "     \n",
    "('neg', tensor(0), tensor([0.8786, 0.1214]))\n",
    "Here we can see the model has considered the review to be positive. The second part of the result is the index of \"pos\" in our data vocabulary and the last part is the probabilities attributed to each class (99.6% for \"pos\" and 0.4% for \"neg\").\n",
    "\n",
    "Now it's your turn! Write your own mini movie review, or copy one from the internet, and you can see what this model thinks about it.\n",
    "\n",
    "Sidebar: The Order Matters\n",
    "In a Jupyter notebook, the order in which you execute each cell is very important. It's not like Excel, where everything gets updated as soon as you type something anywhere—it has an inner state that gets updated each time you execute a cell. For instance, when you run the first cell of the notebook (with the \"CLICK ME\" comment), you create an object called learn that contains a model and data for an image classification problem. If we were to run the cell just shown in the text (the one that predicts if a review is good or not) straight after, we would get an error as this learn object does not contain a text classification model. This cell needs to be run after the one containing:\n",
    "\n",
    "from fastai.text.all import *\n",
    "\n",
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, \n",
    "                                metrics=accuracy)\n",
    "learn.fine_tune(4, 1e-2)\n",
    "The outputs themselves can be deceiving, because they include the results of the last time the cell was executed; if you change the code inside a cell without executing it, the old (misleading) results will remain.\n",
    "\n",
    "Except when we mention it explicitly, the notebooks provided on the book website are meant to be run in order, from top to bottom. In general, when experimenting, you will find yourself executing cells in any order to go fast (which is a super neat feature of Jupyter Notebook), but once you have explored and arrived at the final version of your code, make sure you can run the cells of your notebooks in order (your future self won't necessarily remember the convoluted path you took otherwise!).\n",
    "\n",
    "In command mode, pressing 0 twice will restart the kernel (which is the engine powering your notebook). This will wipe your state clean and make it as if you had just started in the notebook. Choose Run All Above from the Cell menu to run all cells above the point where you are. We have found this to be very useful when developing the fastai library.\n",
    "\n",
    "End sidebar\n",
    "If you ever have any questions about a fastai method, you should use the function doc, passing it the method name:\n",
    "\n",
    "doc(learn.predict)\n",
    "This will make a small window pop up with content like this:\n",
    "\n",
    "\n",
    "A brief one-line explanation is provided by doc. The \"Show in docs\" link takes you to the full documentation, where you'll find all the details and lots of examples. Also, most of fastai's methods are just a handful of lines, so you can click the \"source\" link to see exactly what's going on behind the scenes.\n",
    "\n",
    "Let's move on to something much less sexy, but perhaps significantly more widely commercially useful: building models from plain tabular data.\n",
    "\n",
    "jargon: Tabular: Data that is in the form of a table, such as from a spreadsheet, database, or CSV file. A tabular model is a model that tries to predict one column of a table based on information in other columns of the table.\n",
    "\n",
    "It turns out that looks very similar too. Here is the code necessary to train a model that will predict whether a person is a high-income earner, based on their socioeconomic background:\n",
    "\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "     \n",
    "As you see, we had to tell fastai which columns are categorical (that is, contain values that are one of a discrete set of choices, such as occupation) and which are continuous (that is, contain a number that represents a quantity, such as age).\n",
    "\n",
    "There is no pretrained model available for this task (in general, pretrained models are not widely available for any tabular modeling tasks, although some organizations have created them for internal use), so we don't use fine_tune in this case. Instead we use fit_one_cycle, the most commonly used method for training fastai models from scratch (i.e. without transfer learning):\n",
    "\n",
    "\n",
    "learn.fit_one_cycle(3)\n",
    "     \n",
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.372397\t0.357177\t0.832463\t00:08\n",
    "1\t0.351544\t0.341505\t0.841523\t00:08\n",
    "2\t0.338763\t0.339184\t0.845670\t00:08\n",
    "This model is using the Adult dataset, from the paper \"Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid\" by Rob Kohavi, which contains some demographic data about individuals (like their education, marital status, race, sex, and whether or not they have an annual income greater than $50k). The model is over 80% accurate, and took around 30 seconds to train.\n",
    "\n",
    "Let's look at one more. Recommendation systems are very important, particularly in e-commerce. Companies like Amazon and Netflix try hard to recommend products or movies that users might like. Here's how to train a model that will predict movies people might like, based on their previous viewing habits, using the MovieLens dataset:\n",
    "\n",
    "\n",
    "from fastai.collab import *\n",
    "path = untar_data(URLs.ML_SAMPLE)\n",
    "dls = CollabDataLoaders.from_csv(path/'ratings.csv')\n",
    "learn = collab_learner(dls, y_range=(0.5,5.5))\n",
    "learn.fine_tune(10)\n",
    "     \n",
    "epoch\ttrain_loss\tvalid_loss\ttime\n",
    "0\t1.510897\t1.410028\t00:00\n",
    "epoch\ttrain_loss\tvalid_loss\ttime\n",
    "0\t1.375435\t1.350930\t00:00\n",
    "1\t1.270062\t1.173962\t00:00\n",
    "2\t1.023159\t0.879298\t00:00\n",
    "3\t0.797398\t0.739787\t00:00\n",
    "4\t0.685500\t0.700903\t00:00\n",
    "5\t0.646508\t0.686387\t00:00\n",
    "6\t0.623985\t0.681087\t00:00\n",
    "7\t0.606319\t0.676885\t00:00\n",
    "8\t0.606975\t0.675833\t00:00\n",
    "9\t0.602670\t0.675682\t00:00\n",
    "This model is predicting movie ratings on a scale of 0.5 to 5.0 to within around 0.6 average error. Since we're predicting a continuous number, rather than a category, we have to tell fastai what range our target has, using the y_range parameter.\n",
    "\n",
    "Although we're not actually using a pretrained model (for the same reason that we didn't for the tabular model), this example shows that fastai lets us use fine_tune anyway in this case (you'll learn how and why this works in <<chapter_pet_breeds>>). Sometimes it's best to experiment with fine_tune versus fit_one_cycle to see which works best for your dataset.\n",
    "\n",
    "We can use the same show_results call we saw earlier to view a few examples of user and movie IDs, actual ratings, and predictions:\n",
    "\n",
    "\n",
    "learn.show_results()\n",
    "     \n",
    "userId\tmovieId\trating\trating_pred\n",
    "0\t66.0\t79.0\t4.0\t3.978900\n",
    "1\t97.0\t15.0\t4.0\t3.851795\n",
    "2\t55.0\t79.0\t3.5\t3.945623\n",
    "3\t98.0\t91.0\t4.0\t4.458704\n",
    "4\t53.0\t7.0\t5.0\t4.670005\n",
    "5\t26.0\t69.0\t5.0\t4.319870\n",
    "6\t81.0\t16.0\t4.5\t4.426761\n",
    "7\t80.0\t7.0\t4.0\t4.046183\n",
    "8\t51.0\t94.0\t5.0\t3.499996\n",
    "Sidebar: Datasets: Food for Models\n",
    "You’ve already seen quite a few models in this section, each one trained using a different dataset to do a different task. In machine learning and deep learning, we can’t do anything without data. So, the people that create datasets for us to train our models on are the (often underappreciated) heroes. Some of the most useful and important datasets are those that become important academic baselines; that is, datasets that are widely studied by researchers and used to compare algorithmic changes. Some of these become household names (at least, among households that train models!), such as MNIST, CIFAR-10, and ImageNet.\n",
    "\n",
    "The datasets used in this book have been selected because they provide great examples of the kinds of data that you are likely to encounter, and the academic literature has many examples of model results using these datasets to which you can compare your work.\n",
    "\n",
    "Most datasets used in this book took the creators a lot of work to build. For instance, later in the book we’ll be showing you how to create a model that can translate between French and English. The key input to this is a French/English parallel text corpus prepared back in 2009 by Professor Chris Callison-Burch of the University of Pennsylvania. This dataset contains over 20 million sentence pairs in French and English. He built the dataset in a really clever way: by crawling millions of Canadian web pages (which are often multilingual) and then using a set of simple heuristics to transform URLs of French content onto URLs pointing to the same content in English.\n",
    "\n",
    "As you look at datasets throughout this book, think about where they might have come from, and how they might have been curated. Then think about what kinds of interesting datasets you could create for your own projects. (We’ll even take you step by step through the process of creating your own image dataset soon.)\n",
    "\n",
    "fast.ai has spent a lot of time creating cut-down versions of popular datasets that are specially designed to support rapid prototyping and experimentation, and to be easier to learn with. In this book we will often start by using one of the cut-down versions and later scale up to the full-size version (just as we're doing in this chapter!). In fact, this is how the world’s top practitioners do their modeling in practice; they do most of their experimentation and prototyping with subsets of their data, and only use the full dataset when they have a good understanding of what they have to do.\n",
    "\n",
    "End sidebar\n",
    "Each of the models we trained showed a training and validation loss. A good validation set is one of the most important pieces of the training process. Let's see why and learn how to create one.\n",
    "\n",
    "Validation Sets and Test Sets\n",
    "As we've discussed, the goal of a model is to make predictions about data. But the model training process is fundamentally dumb. If we trained a model with all our data, and then evaluated the model using that same data, we would not be able to tell how well our model can perform on data it hasn’t seen. Without this very valuable piece of information to guide us in training our model, there is a very good chance it would become good at making predictions about that data but would perform poorly on new data.\n",
    "\n",
    "To avoid this, our first step was to split our dataset into two sets: the training set (which our model sees in training) and the validation set, also known as the development set (which is used only for evaluation). This lets us test that the model learns lessons from the training data that generalize to new data, the validation data.\n",
    "\n",
    "One way to understand this situation is that, in a sense, we don't want our model to get good results by \"cheating.\" If it makes an accurate prediction for a data item, that should be because it has learned characteristics of that kind of item, and not because the model has been shaped by actually having seen that particular item.\n",
    "\n",
    "Splitting off our validation data means our model never sees it in training and so is completely untainted by it, and is not cheating in any way. Right?\n",
    "\n",
    "In fact, not necessarily. The situation is more subtle. This is because in realistic scenarios we rarely build a model just by training its weight parameters once. Instead, we are likely to explore many versions of a model through various modeling choices regarding network architecture, learning rates, data augmentation strategies, and other factors we will discuss in upcoming chapters. Many of these choices can be described as choices of hyperparameters. The word reflects that they are parameters about parameters, since they are the higher-level choices that govern the meaning of the weight parameters.\n",
    "\n",
    "The problem is that even though the ordinary training process is only looking at predictions on the training data when it learns values for the weight parameters, the same is not true of us. We, as modelers, are evaluating the model by looking at predictions on the validation data when we decide to explore new hyperparameter values! So subsequent versions of the model are, indirectly, shaped by us having seen the validation data. Just as the automatic training process is in danger of overfitting the training data, we are in danger of overfitting the validation data through human trial and error and exploration.\n",
    "\n",
    "The solution to this conundrum is to introduce another level of even more highly reserved data, the test set. Just as we hold back the validation data from the training process, we must hold back the test set data even from ourselves. It cannot be used to improve the model; it can only be used to evaluate the model at the very end of our efforts. In effect, we define a hierarchy of cuts of our data, based on how fully we want to hide it from training and modeling processes: training data is fully exposed, the validation data is less exposed, and test data is totally hidden. This hierarchy parallels the different kinds of modeling and evaluation processes themselves—the automatic training process with back propagation, the more manual process of trying different hyper-parameters between training sessions, and the assessment of our final result.\n",
    "\n",
    "The test and validation sets should have enough data to ensure that you get a good estimate of your accuracy. If you're creating a cat detector, for instance, you generally want at least 30 cats in your validation set. That means that if you have a dataset with thousands of items, using the default 20% validation set size may be more than you need. On the other hand, if you have lots of data, using some of it for validation probably doesn't have any downsides.\n",
    "\n",
    "Having two levels of \"reserved data\"—a validation set and a test set, with one level representing data that you are virtually hiding from yourself—may seem a bit extreme. But the reason it is often necessary is because models tend to gravitate toward the simplest way to do good predictions (memorization), and we as fallible humans tend to gravitate toward fooling ourselves about how well our models are performing. The discipline of the test set helps us keep ourselves intellectually honest. That doesn't mean we always need a separate test set—if you have very little data, you may need to just have a validation set—but generally it's best to use one if at all possible.\n",
    "\n",
    "This same discipline can be critical if you intend to hire a third party to perform modeling work on your behalf. A third party might not understand your requirements accurately, or their incentives might even encourage them to misunderstand them. A good test set can greatly mitigate these risks and let you evaluate whether their work solves your actual problem.\n",
    "\n",
    "To put it bluntly, if you're a senior decision maker in your organization (or you're advising senior decision makers), the most important takeaway is this: if you ensure that you really understand what test and validation sets are and why they're important, then you'll avoid the single biggest source of failures we've seen when organizations decide to use AI. For instance, if you're considering bringing in an external vendor or service, make sure that you hold out some test data that the vendor never gets to see. Then you check their model on your test data, using a metric that you choose based on what actually matters to you in practice, and you decide what level of performance is adequate. (It's also a good idea for you to try out some simple baseline yourself, so you know what a really simple model can achieve. Often it'll turn out that your simple model performs just as well as one produced by an external \"expert\"!)\n",
    "\n",
    "Use Judgment in Defining Test Sets\n",
    "To do a good job of defining a validation set (and possibly a test set), you will sometimes want to do more than just randomly grab a fraction of your original dataset. Remember: a key property of the validation and test sets is that they must be representative of the new data you will see in the future. This may sound like an impossible order! By definition, you haven’t seen this data yet. But you usually still do know some things.\n",
    "\n",
    "It's instructive to look at a few example cases. Many of these examples come from predictive modeling competitions on the Kaggle platform, which is a good representation of problems and methods you might see in practice.\n",
    "\n",
    "One case might be if you are looking at time series data. For a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates you are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future). If your data includes the date and you are building a model to use in the future, you will want to choose a continuous section with the latest dates as your validation set (for instance, the last two weeks or last month of available data).\n",
    "\n",
    "Suppose you want to split the time series data in <> into training and validation sets.\n",
    "\n",
    "A serie of values\n",
    "A random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you'll need in production), as we can see in <>.\n",
    "\n",
    "Random training subset\n",
    "Instead, use the earlier data as your training set (and the later data for the validation set), as shown in <>.\n",
    "\n",
    "Training subset using the data up to a certain timestamp\n",
    "For example, Kaggle had a competition to predict the sales in a chain of Ecuadorian grocery stores. Kaggle's training data ran from Jan 1 2013 to Aug 15 2017, and the test data spanned Aug 16 2017 to Aug 31 2017. That way, the competition organizer ensured that entrants were making predictions for a time period that was in the future, from the perspective of their model. This is similar to the way quant hedge fund traders do back-testing to check whether their models are predictive of future periods, based on past data.\n",
    "\n",
    "A second common case is when you can easily anticipate ways the data you will be making predictions for in production may be qualitatively different from the data you have to train your model with.\n",
    "\n",
    "In the Kaggle distracted driver competition, the independent variables are pictures of drivers at the wheel of a car, and the dependent variables are categories such as texting, eating, or safely looking ahead. Lots of pictures are of the same drivers in different positions, as we can see in <<img_driver>>. If you were an insurance company building a model from this data, note that you would be most interested in how the model performs on drivers it hasn't seen before (since you would likely have training data only for a small group of people). In recognition of this, the test data for the competition consists of images of people that don't appear in the training set.\n",
    "\n",
    "Two pictures from the training data, showing the same driver\n",
    "If you put one of the images in <<img_driver>> in your training set and one in the validation set, your model will have an easy time making a prediction for the one in the validation set, so it will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model might be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc.).\n",
    "\n",
    "A similar dynamic was at work in the Kaggle fisheries competition to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations. The test set consisted of boats that didn't appear in the training data. This means that you'd want your validation set to include boats that are not in the training set.\n",
    "\n",
    "Sometimes it may not be clear how your validation data will differ. For instance, for a problem using satellite imagery, you'd need to gather more information on whether the training set just contained certain geographic locations, or if it came from geographically scattered data.\n",
    "\n",
    "Now that you have gotten a taste of how to build a model, you can decide what you want to dig into next.\n",
    "\n",
    "A Choose Your Own Adventure moment\n",
    "If you would like to learn more about how to use deep learning models in practice, including how to identify and fix errors, create a real working web application, and avoid your model causing unexpected harm to your organization or society more generally, then keep reading the next two chapters. If you would like to start learning the foundations of how deep learning works under the hood, skip to <<chapter_mnist_basics>>. (Did you ever read Choose Your Own Adventure books as a kid? Well, this is kind of like that… except with more deep learning than that book series contained.)\n",
    "\n",
    "You will need to read all these chapters to progress further in the book, but it is totally up to you which order you read them in. They don't depend on each other. If you skip ahead to <<chapter_mnist_basics>>, we will remind you at the end to come back and read the chapters you skipped over before you go any further.\n",
    "\n",
    "Questionnaire\n",
    "It can be hard to know in pages and pages of prose what the key things are that you really need to focus on and remember. So, we've prepared a list of questions and suggested steps to complete at the end of each chapter. All the answers are in the text of the chapter, so if you're not sure about anything here, reread that part of the text and make sure you understand it. Answers to all these questions are also available on the book's website. You can also visit the forums if you get stuck to get help from other folks studying this material.\n",
    "\n",
    "For more questions, including detailed answers and links to the video timeline, have a look at Radek Osmulski's aiquizzes.\n",
    "\n",
    "Do you need these for deep learning?\n",
    "\n",
    "Lots of math T / F\n",
    "Lots of data T / F\n",
    "Lots of expensive computers T / F\n",
    "A PhD T / F\n",
    "Name five areas where deep learning is now the best in the world.\n",
    "\n",
    "What was the name of the first device that was based on the principle of the artificial neuron?\n",
    "\n",
    "Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n",
    "\n",
    "What were the two theoretical misunderstandings that held back the field of neural networks?\n",
    "\n",
    "What is a GPU?\n",
    "\n",
    "Open a notebook and execute a cell containing: 1+1. What happens?\n",
    "\n",
    "Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.\n",
    "\n",
    "Complete the Jupyter Notebook online appendix.\n",
    "\n",
    "Why is it hard to use a traditional computer program to recognize images in a photo?\n",
    "\n",
    "What did Samuel mean by \"weight assignment\"?\n",
    "\n",
    "What term do we normally use in deep learning for what Samuel called \"weights\"?\n",
    "\n",
    "Draw a picture that summarizes Samuel's view of a machine learning model.\n",
    "\n",
    "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
    "\n",
    "What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?\n",
    "\n",
    "What do you need in order to train a model?\n",
    "\n",
    "How could a feedback loop impact the rollout of a predictive policing model?\n",
    "\n",
    "Do we always have to use 224×224-pixel images with the cat recognition model?\n",
    "\n",
    "What is the difference between classification and regression?\n",
    "\n",
    "What is a validation set? What is a test set? Why do we need them?\n",
    "\n",
    "What will fastai do if you don't provide a validation set?\n",
    "\n",
    "Can we always use a random sample for a validation set? Why or why not?\n",
    "\n",
    "What is overfitting? Provide an example.\n",
    "\n",
    "What is a metric? How does it differ from \"loss\"?\n",
    "\n",
    "How can pretrained models help?\n",
    "\n",
    "What is the \"head\" of a model?\n",
    "\n",
    "What kinds of features do the early layers of a CNN find? How about the later layers?\n",
    "\n",
    "Are image models only useful for photos?\n",
    "\n",
    "What is an \"architecture\"?\n",
    "\n",
    "What is segmentation?\n",
    "\n",
    "What is y_range used for? When do we need it?\n",
    "\n",
    "What are \"hyperparameters\"?\n",
    "\n",
    "What's the best way to avoid failures when using AI in an organization?\n",
    "\n",
    "Further Research\n",
    "Each chapter also has a \"Further Research\" section that poses questions that aren't fully answered in the text, or gives more advanced assignments. Answers to these questions aren't on the book's website; you'll need to do your own research!\n",
    "\n",
    "Why is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?\n",
    "Try to think of three areas where feedback loops might impact the use of machine learning. See if you can find documented examples of that happening in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
